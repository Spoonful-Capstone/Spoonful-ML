{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is the Training Stage Implementation of [Spoonful Bangkit 2024 Casptone Project](https://github.com/Spoonful-Capstone/Spoonful-ML/tree/master). Go to [this link](https://colab.research.google.com/drive/17vwft3NtaE2tfWTiHliZxBnqm7EDBV-R?usp=sharing#scrollTo=P45xPDz_DcqS) if you want to open it on colab"
      ],
      "metadata": {
        "id": "P45xPDz_DcqS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msHKfWGPx7NG"
      },
      "source": [
        "## Install and Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-wjJ4sBhyQla"
      },
      "outputs": [],
      "source": [
        "# @title <p> Install dependencies\n",
        "!pip install roboflow --quiet &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2JylPGa2uGT4"
      },
      "outputs": [],
      "source": [
        "# @title <p>Essential Import\n",
        "import os, shutil, json\n",
        "from PIL import Image\n",
        "from zipfile import ZipFile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np, pandas as pd, random as rd\n",
        "import warnings\n",
        "import pathlib\n",
        "from collections import Counter\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQqVqfYnWR3Y"
      },
      "outputs": [],
      "source": [
        "# @title <p> Import Modelling Dependencies\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications import MobileNet, MobileNetV3Small, EfficientNetB0, EfficientNetB7\n",
        "\n",
        "from roboflow import Roboflow\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Jchrj1Tx-zc"
      },
      "source": [
        "## Get Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDRz6t05rf6U"
      },
      "source": [
        "### Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-aYZUKEYSgG"
      },
      "outputs": [],
      "source": [
        "# @title <p> Make a Helper Function\n",
        "def relocate_dataset(INITIAL_PATH, DATASET_PATH, TRAIN_SIZE, VAL_SIZE):\n",
        "  os.makedirs(DATASET_PATH, exist_ok=True)\n",
        "\n",
        "  for mode in ['train', 'val', 'test']:\n",
        "\n",
        "    os.makedirs(os.path.join(DATASET_PATH, mode), exist_ok=True)\n",
        "    for food in os.listdir(INITIAL_PATH):\n",
        "      os.makedirs(os.path.join(DATASET_PATH, mode, food), exist_ok=True)\n",
        "\n",
        "  for food in os.listdir(INITIAL_PATH):\n",
        "\n",
        "    for i, img in enumerate(os.listdir(os.path.join(INITIAL_PATH, food))):\n",
        "\n",
        "      count_food_img = len(os.listdir(os.path.join(INITIAL_PATH, food)))\n",
        "\n",
        "      if i <= int(TRAIN_SIZE * count_food_img) :\n",
        "        shutil.copy(os.path.join(INITIAL_PATH, food, img), os.path.join(DATASET_PATH, 'train', food, img))\n",
        "\n",
        "      elif i <= int((TRAIN_SIZE + VAL_SIZE) * count_food_img):\n",
        "        shutil.copy(os.path.join(INITIAL_PATH, food, img), os.path.join(DATASET_PATH, 'val', food, img))\n",
        "\n",
        "      elif i > int((TRAIN_SIZE + VAL_SIZE) * count_food_img):\n",
        "        shutil.copy(os.path.join(INITIAL_PATH, food, img), os.path.join(DATASET_PATH, 'test', food, img))\n",
        "\n",
        "  shutil.rmtree(INITIAL_PATH)\n",
        "\n",
        "# @title <p> Print food len\n",
        "def print_dataset_len(DATASET_PATH):\n",
        "  for food in os.listdir(os.path.join(DATASET_PATH, 'train')):\n",
        "\n",
        "    train_food_path = os.listdir(os.path.join(DATASET_PATH, 'train', food))\n",
        "    val_food_path = os.listdir(os.path.join(DATASET_PATH, 'val', food))\n",
        "    test_food_path = os.listdir(os.path.join(DATASET_PATH, 'test', food))\n",
        "\n",
        "    print(f\"{food} : \")\n",
        "    print(f\"Train : {len(train_food_path)} | Val : {len(val_food_path)} | Test : {len(test_food_path)}\")\n",
        "\n",
        "\n",
        "def import_kaggle_json():\n",
        "  from google.colab import files\n",
        "  files.upload()\n",
        "\n",
        "  ! mkdir ~/.kaggle\n",
        "  ! cp kaggle.json ~/.kaggle\n",
        "  ! chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOcIMeRTXTYR",
        "outputId": "7874d35b-133a-4bab-ebf6-8736684b6474",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading Dataset Version Zip in Indonesian-Food-1 to folder:: 100%|██████████| 11003/11003 [00:00<00:00, 27156.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to Indonesian-Food-1 in folder:: 100%|██████████| 962/962 [00:00<00:00, 8954.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16. Soto Banjar : \n",
            "Train : 33 | Val : 8 | Test : 3\n",
            "14. Sate Madura : \n",
            "Train : 34 | Val : 12 | Test : 9\n",
            "12. Rawon : \n",
            "Train : 40 | Val : 10 | Test : 5\n",
            "04. Gudeg : \n",
            "Train : 39 | Val : 10 | Test : 5\n",
            "08. Nasi Pecel : \n",
            "Train : 35 | Val : 8 | Test : 7\n",
            "01. Ayam Betutu : \n",
            "Train : 37 | Val : 10 | Test : 8\n",
            "07. Nasi Kuning : \n",
            "Train : 23 | Val : 11 | Test : 4\n",
            "05. Kerak Telor : \n",
            "Train : 36 | Val : 6 | Test : 3\n",
            "03. Coto Makassar : \n",
            "Train : 35 | Val : 11 | Test : 3\n",
            "09. Papeda : \n",
            "Train : 41 | Val : 11 | Test : 3\n",
            "15. Serabi : \n",
            "Train : 39 | Val : 9 | Test : 7\n",
            "11. Peuyeum : \n",
            "Train : 37 | Val : 16 | Test : 2\n",
            "18. Tahu Sumedang : \n",
            "Train : 40 | Val : 5 | Test : 3\n",
            "02. Beberuk Terong : \n",
            "Train : 26 | Val : 10 | Test : 4\n",
            "06. Mie Aceh : \n",
            "Train : 28 | Val : 8 | Test : 4\n",
            "10. Pempek : \n",
            "Train : 37 | Val : 14 | Test : 4\n",
            "17. Soto Lamongan : \n",
            "Train : 39 | Val : 10 | Test : 6\n",
            "13. Rendang : \n",
            "Train : 36 | Val : 10 | Test : 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title <p>Choose Datasets\n",
        "# Kaggle Food Image Classification https://www.kaggle.com/datasets/harishkumardatalab/food-image-classification-dataset\n",
        "Kaggle_Dataset   = False        #@param {type:\"boolean\"}\n",
        "# Roboflow Indonesian Food Image Classification https://universe.roboflow.com/bangkit/indonesian-food-pedsx\n",
        "Roboflow_Dataset = True         #@param {type:\"boolean\"}\n",
        "\n",
        "if os.path.isdir('dataset'):\n",
        "  !rm -r 'dataset'\n",
        "if os.path.isdir('Food Classification dataset'):\n",
        "  !rm -r 'Food Classification dataset'\n",
        "if os.path.isdir('Indonesian-Food-1'):\n",
        "  !rm -r 'Indonesian-Food-1'\n",
        "\n",
        "if Kaggle_Dataset :\n",
        "  if not os.path.isfile('kaggle.json'):\n",
        "    import_kaggle_json()\n",
        "  !kaggle datasets download 'harishkumardatalab/food-image-classification-dataset'\n",
        "  !unzip '/content/food-image-classification-dataset.zip' &> /dev/null\n",
        "  !rm '/content/food-image-classification-dataset.zip'\n",
        "\n",
        "  DATASET_PATH = 'dataset'\n",
        "\n",
        "  TRAIN_SIZE = 0.8\n",
        "  VAL_SIZE = 0.1\n",
        "  relocate_dataset('Food Classification dataset', DATASET_PATH, TRAIN_SIZE, VAL_SIZE)\n",
        "\n",
        "if Roboflow_Dataset :\n",
        "\n",
        "  rf = Roboflow(api_key=\"1UnUQCCfSuu44HS6CrHe\")\n",
        "  project = rf.workspace(\"bangkit\").project(\"indonesian-food-pedsx\")\n",
        "  version = project.version(1)\n",
        "  dataset = version.download(\"folder\")\n",
        "\n",
        "  os.rename('Indonesian-Food-1/valid', 'Indonesian-Food-1/val')\n",
        "  DATASET_PATH = 'Indonesian-Food-1'\n",
        "\n",
        "print_dataset_len(DATASET_PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdtUk5fpyA0W"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h5RZuuPieHJh",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title <p> Make a Function to Create Generator\n",
        "def create_generator(train_path,\n",
        "                     val_path,\n",
        "                     test_path,\n",
        "                     BATCH_SIZE = 32,\n",
        "                     IMG_SHAPE=256,\n",
        "                     class_mode='categorical',\n",
        "                     ):\n",
        "\n",
        "  train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        "  )\n",
        "\n",
        "  test_len = sum([len(os.listdir(os.path.join(TEST_PATH, label))) for label in os.listdir(TEST_PATH)])\n",
        "\n",
        "  test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(train_path, batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=True, class_mode=class_mode,\n",
        "                                                     target_size=(IMG_SHAPE, IMG_SHAPE))\n",
        "  val_generator = test_datagen.flow_from_directory(val_path, batch_size=BATCH_SIZE,\n",
        "                                                     shuffle=False, class_mode=class_mode,\n",
        "                                                     target_size=(IMG_SHAPE, IMG_SHAPE))\n",
        "  test_generator = test_datagen.flow_from_directory(test_path, batch_size=test_len,\n",
        "                                                     shuffle=False, class_mode=class_mode,\n",
        "                                                     target_size=(IMG_SHAPE, IMG_SHAPE))\n",
        "\n",
        "  return train_generator, val_generator, test_generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhawlFg-yCPb",
        "outputId": "a51f4378-fa84-4942-e109-28ea7f246df5",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 635 images belonging to 18 classes.\n",
            "Found 179 images belonging to 18 classes.\n",
            "Found 89 images belonging to 18 classes.\n"
          ]
        }
      ],
      "source": [
        "# @title <p> Make a dataset object\n",
        "BATCH_SIZE = 32 #@param{type:\"integer\"}\n",
        "IMG_SHAPE = 256 #@param{type:\"integer\"}\n",
        "\n",
        "COUNT_LABEL = len(os.listdir(os.path.join(DATASET_PATH, 'train')))\n",
        "\n",
        "TRAIN_PATH = os.path.join(DATASET_PATH, 'train')\n",
        "VAL_PATH = os.path.join(DATASET_PATH, 'val')\n",
        "TEST_PATH = os.path.join(DATASET_PATH, 'test')\n",
        "\n",
        "train_generator, val_generator, test_generator = create_generator(TRAIN_PATH, VAL_PATH, TEST_PATH, BATCH_SIZE, IMG_SHAPE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnGyG10hyFUk"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ8tFBdMUexl"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yIIHIFcyG8A"
      },
      "outputs": [],
      "source": [
        "# @title <p> Finetune the Inception Model Functoin\n",
        "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
        "\n",
        "dense_layer = 128 #@param {type:'raw'}\n",
        "\n",
        "\n",
        "def inception_model(IMG_SHAPE, COUNT_LABEL):\n",
        "  !wget --no-check-certificate \\\n",
        "      https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "      -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "  local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "  pre_trained_model = InceptionV3(input_shape = (IMG_SHAPE, IMG_SHAPE, 3),\n",
        "                                  include_top = False,\n",
        "                                  weights = None)\n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  # Choose `mixed7` as the last layer of your base model\n",
        "  last_layer = pre_trained_model.get_layer('mixed7')\n",
        "  print('last layer output shape: ', last_layer.output_shape)\n",
        "  last_output = last_layer.output\n",
        "\n",
        "  x = layers.Flatten()(last_output)\n",
        "  x = layers.Dense(dense_layer, activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense  (COUNT_LABEL, activation='softmax')(x)\n",
        "\n",
        "  model = Model(pre_trained_model.input, x)\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p> Finetune the MobileNet Model Functoin\n",
        "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
        "\n",
        "# dense_layer = 1024 #@param {type:'raw'}\n",
        "\n",
        "def mobilenet_model(IMG_SHAPE, COUNT_LABEL):\n",
        "  # !wget https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
        "  local_weights_file = 'mobilenet_1_0_224_tf_no_top.h5'\n",
        "  pre_trained_model = MobileNet(include_top=False, input_shape=(IMG_SHAPE, IMG_SHAPE, 3))\n",
        "\n",
        "  pre_trained_model.load_weights(local_weights_file)\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  last_layer = pre_trained_model.get_layer('conv_pw_13_bn')\n",
        "  print('last layer output shape: ', last_layer.output_shape)\n",
        "  last_output = last_layer.output\n",
        "\n",
        "  x = layers.Flatten()(last_output)\n",
        "  x = layers.Dense(dense_layer, activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense  (COUNT_LABEL, activation='softmax')(x)\n",
        "\n",
        "  model = Model(pre_trained_model.input, x)\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "metadata": {
        "id": "Bu_RnG1osxKu",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p> Finetune the EfficientNet Model Functoin\n",
        "# Download the pre-trained weights. No top means it excludes the fully connected layer it uses for classification.\n",
        "\n",
        "dense_layer = 256 #@param {type:'raw'}\n",
        "\n",
        "def efficientnet_model(IMG_SHAPE, COUNT_LABEL):\n",
        "  # !wget --no-check-certificate \\\n",
        "  #     https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "  #     -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "  # local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "  pre_trained_model = EfficientNetB7 (input_shape = (IMG_SHAPE, IMG_SHAPE, 3),\n",
        "                                  include_top = False,\n",
        "                                  weights = 'imagenet')\n",
        "\n",
        "  # pre_trained_model.load_weights(local_weights_file)\n",
        "  for layer in pre_trained_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  last_layer = pre_trained_model.get_layer('top_bn')\n",
        "  print('last layer output shape: ', last_layer.output_shape)\n",
        "  last_output = last_layer.output\n",
        "\n",
        "  x = layers.Flatten()(last_output)\n",
        "  x = layers.Dense(dense_layer, activation='relu')(x)\n",
        "  x = layers.Dropout(0.2)(x)\n",
        "  x = layers.Dense  (COUNT_LABEL, activation='softmax')(x)\n",
        "\n",
        "  model = Model(pre_trained_model.input, x)\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "metadata": {
        "cellView": "form",
        "id": "f2K59qlW9NdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ch9Fn4QLWGJk"
      },
      "outputs": [],
      "source": [
        "# @title <p> Make a Custom Model Function\n",
        "\n",
        "conv_layer = [16, 32, 64] #@param {type:'raw'}\n",
        "dense_layer_custom = [1024, 32] #@param {type:'raw'}\n",
        "batch_norm = False #@param {type:'raw'}\n",
        "dropout = 0.2 #@param {type:'raw'}\n",
        "\n",
        "def create_costum_model(IMG_SHAPE, COUNT_LABEL):\n",
        "  class ConvBlock(tf.keras.Model):\n",
        "    def __init__(self, units, kernel_size=(3,3), padding=None, batch_norm=True):\n",
        "      super(ConvBlock, self).__init__()\n",
        "      self.conv = tf.keras.layers.Conv2D(units, kernel_size, padding=padding, activation='relu')\n",
        "      if batch_norm :\n",
        "        self.bn = tf.keras.layers.BatchNormalization()\n",
        "      self.maxpool = tf.keras.layers.MaxPool2D((2,2))\n",
        "\n",
        "    def call(self, inputs):\n",
        "      x = self.conv(inputs)\n",
        "      if batch_norm :\n",
        "        x = self.bn(x)\n",
        "\n",
        "      return self.maxpool(x)\n",
        "\n",
        "  class DenseBlock(tf.keras.Model):\n",
        "    def __init__(self, units, dropout=0.2):\n",
        "      super(DenseBlock, self).__init__()\n",
        "      self.linear = tf.keras.layers.Dense(units, activation='relu')\n",
        "      self.dropout = tf.keras.layers.Dropout(0.2)\n",
        "      self.ln = tf.keras.layers.Normalization()\n",
        "\n",
        "    def call(self, inputs):\n",
        "      x = self.linear(inputs)\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      return self.ln(x)\n",
        "\n",
        "  class CustomModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "      super().__init__()\n",
        "      self.conv = {f'convblock{i + 1}' : ConvBlock(filters, (3,3), padding='same') for i, filters in enumerate(conv_layer)}\n",
        "\n",
        "      self.flatten = tf.keras.layers.Flatten()\n",
        "      self.dense = {f'denseblock{i + 1}' : DenseBlock(units) for i, units in enumerate(dense_layer_custom)}\n",
        "\n",
        "      self.out = tf.keras.layers.Dense(COUNT_LABEL, activation='softmax')\n",
        "\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "      for i in range(1, len(self.conv) + 1) :\n",
        "        x = self.conv[f'convblock{i}'](x)\n",
        "      x = self.flatten(x)\n",
        "      for i in range(1, len(self.dense) + 1) :\n",
        "        x = self.dense[f'denseblock{i}'](x)\n",
        "      x = self.out(x)\n",
        "      return x\n",
        "\n",
        "  model = CustomModel()\n",
        "  model.build((None, IMG_SHAPE, IMG_SHAPE, 3))\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7jcy5ixYJeI",
        "outputId": "ccd62842-5abb-47da-b817-febc0b7664b5",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-06-04 08:57:10--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.207, 74.125.197.207, 74.125.135.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M   295MB/s    in 0.3s    \n",
            "\n",
            "2024-06-04 08:57:11 (295 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "last layer output shape:  (None, 14, 14, 768)\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_22 (InputLayer)       [(None, 256, 256, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_376 (Conv2D)         (None, 127, 127, 32)         864       ['input_22[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_376 (B  (None, 127, 127, 32)         96        ['conv2d_376[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_376 (Activation  (None, 127, 127, 32)         0         ['batch_normalization_376[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_377 (Conv2D)         (None, 125, 125, 32)         9216      ['activation_376[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_377 (B  (None, 125, 125, 32)         96        ['conv2d_377[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_377 (Activation  (None, 125, 125, 32)         0         ['batch_normalization_377[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_378 (Conv2D)         (None, 125, 125, 64)         18432     ['activation_377[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_378 (B  (None, 125, 125, 64)         192       ['conv2d_378[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_378 (Activation  (None, 125, 125, 64)         0         ['batch_normalization_378[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_16 (MaxPooli  (None, 62, 62, 64)           0         ['activation_378[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_379 (Conv2D)         (None, 62, 62, 80)           5120      ['max_pooling2d_16[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_379 (B  (None, 62, 62, 80)           240       ['conv2d_379[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_379 (Activation  (None, 62, 62, 80)           0         ['batch_normalization_379[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_380 (Conv2D)         (None, 60, 60, 192)          138240    ['activation_379[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_380 (B  (None, 60, 60, 192)          576       ['conv2d_380[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_380 (Activation  (None, 60, 60, 192)          0         ['batch_normalization_380[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_17 (MaxPooli  (None, 29, 29, 192)          0         ['activation_380[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_384 (Conv2D)         (None, 29, 29, 64)           12288     ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_384 (B  (None, 29, 29, 64)           192       ['conv2d_384[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_384 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_384[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_382 (Conv2D)         (None, 29, 29, 48)           9216      ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_385 (Conv2D)         (None, 29, 29, 96)           55296     ['activation_384[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_382 (B  (None, 29, 29, 48)           144       ['conv2d_382[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_385 (B  (None, 29, 29, 96)           288       ['conv2d_385[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_382 (Activation  (None, 29, 29, 48)           0         ['batch_normalization_382[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_385 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_385[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_36 (Aver  (None, 29, 29, 192)          0         ['max_pooling2d_17[0][0]']    \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_381 (Conv2D)         (None, 29, 29, 64)           12288     ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_383 (Conv2D)         (None, 29, 29, 64)           76800     ['activation_382[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_386 (Conv2D)         (None, 29, 29, 96)           82944     ['activation_385[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_387 (Conv2D)         (None, 29, 29, 32)           6144      ['average_pooling2d_36[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_381 (B  (None, 29, 29, 64)           192       ['conv2d_381[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_383 (B  (None, 29, 29, 64)           192       ['conv2d_383[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_386 (B  (None, 29, 29, 96)           288       ['conv2d_386[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_387 (B  (None, 29, 29, 32)           96        ['conv2d_387[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_381 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_381[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_383 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_383[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_386 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_386[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_387 (Activation  (None, 29, 29, 32)           0         ['batch_normalization_387[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 29, 29, 256)          0         ['activation_381[0][0]',      \n",
            "                                                                     'activation_383[0][0]',      \n",
            "                                                                     'activation_386[0][0]',      \n",
            "                                                                     'activation_387[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_391 (Conv2D)         (None, 29, 29, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_391 (B  (None, 29, 29, 64)           192       ['conv2d_391[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_391 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_391[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_389 (Conv2D)         (None, 29, 29, 48)           12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_392 (Conv2D)         (None, 29, 29, 96)           55296     ['activation_391[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_389 (B  (None, 29, 29, 48)           144       ['conv2d_389[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_392 (B  (None, 29, 29, 96)           288       ['conv2d_392[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_389 (Activation  (None, 29, 29, 48)           0         ['batch_normalization_389[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_392 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_392[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_37 (Aver  (None, 29, 29, 256)          0         ['mixed0[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_388 (Conv2D)         (None, 29, 29, 64)           16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_390 (Conv2D)         (None, 29, 29, 64)           76800     ['activation_389[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_393 (Conv2D)         (None, 29, 29, 96)           82944     ['activation_392[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_394 (Conv2D)         (None, 29, 29, 64)           16384     ['average_pooling2d_37[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_388 (B  (None, 29, 29, 64)           192       ['conv2d_388[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_390 (B  (None, 29, 29, 64)           192       ['conv2d_390[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_393 (B  (None, 29, 29, 96)           288       ['conv2d_393[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_394 (B  (None, 29, 29, 64)           192       ['conv2d_394[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_388 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_388[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_390 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_390[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_393 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_393[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_394 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_394[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 29, 29, 288)          0         ['activation_388[0][0]',      \n",
            "                                                                     'activation_390[0][0]',      \n",
            "                                                                     'activation_393[0][0]',      \n",
            "                                                                     'activation_394[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_398 (Conv2D)         (None, 29, 29, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_398 (B  (None, 29, 29, 64)           192       ['conv2d_398[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_398 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_398[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_396 (Conv2D)         (None, 29, 29, 48)           13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_399 (Conv2D)         (None, 29, 29, 96)           55296     ['activation_398[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_396 (B  (None, 29, 29, 48)           144       ['conv2d_396[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_399 (B  (None, 29, 29, 96)           288       ['conv2d_399[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_396 (Activation  (None, 29, 29, 48)           0         ['batch_normalization_396[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_399 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_399[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_38 (Aver  (None, 29, 29, 288)          0         ['mixed1[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_395 (Conv2D)         (None, 29, 29, 64)           18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_397 (Conv2D)         (None, 29, 29, 64)           76800     ['activation_396[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_400 (Conv2D)         (None, 29, 29, 96)           82944     ['activation_399[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_401 (Conv2D)         (None, 29, 29, 64)           18432     ['average_pooling2d_38[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_395 (B  (None, 29, 29, 64)           192       ['conv2d_395[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_397 (B  (None, 29, 29, 64)           192       ['conv2d_397[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_400 (B  (None, 29, 29, 96)           288       ['conv2d_400[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_401 (B  (None, 29, 29, 64)           192       ['conv2d_401[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_395 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_395[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_397 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_397[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_400 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_400[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_401 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_401[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 29, 29, 288)          0         ['activation_395[0][0]',      \n",
            "                                                                     'activation_397[0][0]',      \n",
            "                                                                     'activation_400[0][0]',      \n",
            "                                                                     'activation_401[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_403 (Conv2D)         (None, 29, 29, 64)           18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_403 (B  (None, 29, 29, 64)           192       ['conv2d_403[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_403 (Activation  (None, 29, 29, 64)           0         ['batch_normalization_403[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_404 (Conv2D)         (None, 29, 29, 96)           55296     ['activation_403[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_404 (B  (None, 29, 29, 96)           288       ['conv2d_404[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_404 (Activation  (None, 29, 29, 96)           0         ['batch_normalization_404[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_402 (Conv2D)         (None, 14, 14, 384)          995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_405 (Conv2D)         (None, 14, 14, 96)           82944     ['activation_404[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_402 (B  (None, 14, 14, 384)          1152      ['conv2d_402[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_405 (B  (None, 14, 14, 96)           288       ['conv2d_405[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_402 (Activation  (None, 14, 14, 384)          0         ['batch_normalization_402[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_405 (Activation  (None, 14, 14, 96)           0         ['batch_normalization_405[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooli  (None, 14, 14, 288)          0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 14, 14, 768)          0         ['activation_402[0][0]',      \n",
            "                                                                     'activation_405[0][0]',      \n",
            "                                                                     'max_pooling2d_18[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_410 (Conv2D)         (None, 14, 14, 128)          98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_410 (B  (None, 14, 14, 128)          384       ['conv2d_410[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_410 (Activation  (None, 14, 14, 128)          0         ['batch_normalization_410[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_411 (Conv2D)         (None, 14, 14, 128)          114688    ['activation_410[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_411 (B  (None, 14, 14, 128)          384       ['conv2d_411[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_411 (Activation  (None, 14, 14, 128)          0         ['batch_normalization_411[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_407 (Conv2D)         (None, 14, 14, 128)          98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_412 (Conv2D)         (None, 14, 14, 128)          114688    ['activation_411[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_407 (B  (None, 14, 14, 128)          384       ['conv2d_407[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_412 (B  (None, 14, 14, 128)          384       ['conv2d_412[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_407 (Activation  (None, 14, 14, 128)          0         ['batch_normalization_407[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_412 (Activation  (None, 14, 14, 128)          0         ['batch_normalization_412[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_408 (Conv2D)         (None, 14, 14, 128)          114688    ['activation_407[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_413 (Conv2D)         (None, 14, 14, 128)          114688    ['activation_412[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_408 (B  (None, 14, 14, 128)          384       ['conv2d_408[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_413 (B  (None, 14, 14, 128)          384       ['conv2d_413[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_408 (Activation  (None, 14, 14, 128)          0         ['batch_normalization_408[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_413 (Activation  (None, 14, 14, 128)          0         ['batch_normalization_413[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_39 (Aver  (None, 14, 14, 768)          0         ['mixed3[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_406 (Conv2D)         (None, 14, 14, 192)          147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_409 (Conv2D)         (None, 14, 14, 192)          172032    ['activation_408[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_414 (Conv2D)         (None, 14, 14, 192)          172032    ['activation_413[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_415 (Conv2D)         (None, 14, 14, 192)          147456    ['average_pooling2d_39[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_406 (B  (None, 14, 14, 192)          576       ['conv2d_406[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_409 (B  (None, 14, 14, 192)          576       ['conv2d_409[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_414 (B  (None, 14, 14, 192)          576       ['conv2d_414[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_415 (B  (None, 14, 14, 192)          576       ['conv2d_415[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_406 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_406[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_409 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_409[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_414 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_414[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_415 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_415[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 14, 14, 768)          0         ['activation_406[0][0]',      \n",
            "                                                                     'activation_409[0][0]',      \n",
            "                                                                     'activation_414[0][0]',      \n",
            "                                                                     'activation_415[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_420 (Conv2D)         (None, 14, 14, 160)          122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_420 (B  (None, 14, 14, 160)          480       ['conv2d_420[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_420 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_420[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_421 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_420[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_421 (B  (None, 14, 14, 160)          480       ['conv2d_421[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_421 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_421[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_417 (Conv2D)         (None, 14, 14, 160)          122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_422 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_421[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_417 (B  (None, 14, 14, 160)          480       ['conv2d_417[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_422 (B  (None, 14, 14, 160)          480       ['conv2d_422[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_417 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_417[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_422 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_422[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_418 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_417[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_423 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_422[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_418 (B  (None, 14, 14, 160)          480       ['conv2d_418[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_423 (B  (None, 14, 14, 160)          480       ['conv2d_423[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_418 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_418[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_423 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_423[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_40 (Aver  (None, 14, 14, 768)          0         ['mixed4[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_416 (Conv2D)         (None, 14, 14, 192)          147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_419 (Conv2D)         (None, 14, 14, 192)          215040    ['activation_418[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_424 (Conv2D)         (None, 14, 14, 192)          215040    ['activation_423[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_425 (Conv2D)         (None, 14, 14, 192)          147456    ['average_pooling2d_40[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_416 (B  (None, 14, 14, 192)          576       ['conv2d_416[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_419 (B  (None, 14, 14, 192)          576       ['conv2d_419[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_424 (B  (None, 14, 14, 192)          576       ['conv2d_424[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_425 (B  (None, 14, 14, 192)          576       ['conv2d_425[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_416 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_416[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_419 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_419[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_424 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_424[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_425 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_425[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 14, 14, 768)          0         ['activation_416[0][0]',      \n",
            "                                                                     'activation_419[0][0]',      \n",
            "                                                                     'activation_424[0][0]',      \n",
            "                                                                     'activation_425[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_430 (Conv2D)         (None, 14, 14, 160)          122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_430 (B  (None, 14, 14, 160)          480       ['conv2d_430[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_430 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_430[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_431 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_430[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_431 (B  (None, 14, 14, 160)          480       ['conv2d_431[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_431 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_431[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_427 (Conv2D)         (None, 14, 14, 160)          122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_432 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_431[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_427 (B  (None, 14, 14, 160)          480       ['conv2d_427[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_432 (B  (None, 14, 14, 160)          480       ['conv2d_432[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_427 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_427[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_432 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_432[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_428 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_427[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_433 (Conv2D)         (None, 14, 14, 160)          179200    ['activation_432[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_428 (B  (None, 14, 14, 160)          480       ['conv2d_428[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_433 (B  (None, 14, 14, 160)          480       ['conv2d_433[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_428 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_428[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_433 (Activation  (None, 14, 14, 160)          0         ['batch_normalization_433[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_41 (Aver  (None, 14, 14, 768)          0         ['mixed5[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_426 (Conv2D)         (None, 14, 14, 192)          147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_429 (Conv2D)         (None, 14, 14, 192)          215040    ['activation_428[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_434 (Conv2D)         (None, 14, 14, 192)          215040    ['activation_433[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_435 (Conv2D)         (None, 14, 14, 192)          147456    ['average_pooling2d_41[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_426 (B  (None, 14, 14, 192)          576       ['conv2d_426[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_429 (B  (None, 14, 14, 192)          576       ['conv2d_429[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_434 (B  (None, 14, 14, 192)          576       ['conv2d_434[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_435 (B  (None, 14, 14, 192)          576       ['conv2d_435[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_426 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_426[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_429 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_429[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_434 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_434[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_435 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_435[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 14, 14, 768)          0         ['activation_426[0][0]',      \n",
            "                                                                     'activation_429[0][0]',      \n",
            "                                                                     'activation_434[0][0]',      \n",
            "                                                                     'activation_435[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_440 (Conv2D)         (None, 14, 14, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_440 (B  (None, 14, 14, 192)          576       ['conv2d_440[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_440 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_440[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_441 (Conv2D)         (None, 14, 14, 192)          258048    ['activation_440[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_441 (B  (None, 14, 14, 192)          576       ['conv2d_441[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_441 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_441[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_437 (Conv2D)         (None, 14, 14, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_442 (Conv2D)         (None, 14, 14, 192)          258048    ['activation_441[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_437 (B  (None, 14, 14, 192)          576       ['conv2d_437[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_442 (B  (None, 14, 14, 192)          576       ['conv2d_442[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_437 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_437[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_442 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_442[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_438 (Conv2D)         (None, 14, 14, 192)          258048    ['activation_437[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_443 (Conv2D)         (None, 14, 14, 192)          258048    ['activation_442[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_438 (B  (None, 14, 14, 192)          576       ['conv2d_438[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_443 (B  (None, 14, 14, 192)          576       ['conv2d_443[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_438 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_438[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_443 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_443[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_42 (Aver  (None, 14, 14, 768)          0         ['mixed6[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_436 (Conv2D)         (None, 14, 14, 192)          147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_439 (Conv2D)         (None, 14, 14, 192)          258048    ['activation_438[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_444 (Conv2D)         (None, 14, 14, 192)          258048    ['activation_443[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_445 (Conv2D)         (None, 14, 14, 192)          147456    ['average_pooling2d_42[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_436 (B  (None, 14, 14, 192)          576       ['conv2d_436[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_439 (B  (None, 14, 14, 192)          576       ['conv2d_439[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_444 (B  (None, 14, 14, 192)          576       ['conv2d_444[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_445 (B  (None, 14, 14, 192)          576       ['conv2d_445[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_436 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_436[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_439 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_439[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_444 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_444[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_445 (Activation  (None, 14, 14, 192)          0         ['batch_normalization_445[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 14, 14, 768)          0         ['activation_436[0][0]',      \n",
            "                                                                     'activation_439[0][0]',      \n",
            "                                                                     'activation_444[0][0]',      \n",
            "                                                                     'activation_445[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_8 (Flatten)         (None, 150528)               0         ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 128)                  1926771   ['flatten_8[0][0]']           \n",
            "                                                          2                                       \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)         (None, 128)                  0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 18)                   2322      ['dropout_8[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 28245298 (107.75 MB)\n",
            "Trainable params: 19270034 (73.51 MB)\n",
            "Non-trainable params: 8975264 (34.24 MB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# @title <p> Make a Model\n",
        "inception = True #@param {type:'boolean'}\n",
        "mobilenet = False #@param {type:'boolean'}\n",
        "efficientnet = False #@param {type:'boolean'}\n",
        "costum = False #@param {type:'boolean'}\n",
        "\n",
        "if inception :\n",
        "  model = inception_model(IMG_SHAPE, COUNT_LABEL)\n",
        "if mobilenet :\n",
        "  model = mobilenet_model(IMG_SHAPE, COUNT_LABEL)\n",
        "if efficientnet :\n",
        "  model = efficientnet_model(IMG_SHAPE, COUNT_LABEL)\n",
        "if costum :\n",
        "  model = create_costum_model(IMG_SHAPE, COUNT_LABEL)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52Ogn3rHUiaG"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9d9mxyAPSUD",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title <p> Make a Training Function\n",
        "def train_model(model,\n",
        "                train_generator, val_generator,\n",
        "                EPOCHS, LEARNING_RATE, checkpoint_path) :\n",
        "  # Compile Model\n",
        "  model.compile(optimizer = Adam(learning_rate=LEARNING_RATE),\n",
        "                loss = 'categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "\n",
        "  cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "  # Train Model\n",
        "  history = model.fit(\n",
        "              train_generator,\n",
        "              validation_data = val_generator,\n",
        "              steps_per_epoch = len(train_generator),\n",
        "              epochs = EPOCHS,\n",
        "              validation_steps =  len(val_generator),\n",
        "              verbose = 2,\n",
        "              callbacks=[cp_callback])\n",
        "\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1KV-PLFTX8O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1865e37b-5c55-4a9a-9f43-829eec683874",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 1: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 21s - loss: 4.2407 - accuracy: 0.1307 - val_loss: 2.4532 - val_accuracy: 0.2682 - 21s/epoch - 1s/step\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 2: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 17s - loss: 2.4601 - accuracy: 0.2299 - val_loss: 2.0816 - val_accuracy: 0.3240 - 17s/epoch - 850ms/step\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 3: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 2.0625 - accuracy: 0.3528 - val_loss: 1.7787 - val_accuracy: 0.4860 - 18s/epoch - 924ms/step\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 4: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 1.7062 - accuracy: 0.4646 - val_loss: 1.5604 - val_accuracy: 0.5140 - 18s/epoch - 913ms/step\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 5: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 14s - loss: 1.4794 - accuracy: 0.5276 - val_loss: 1.3014 - val_accuracy: 0.6257 - 14s/epoch - 695ms/step\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 6: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 43s - loss: 1.3389 - accuracy: 0.5906 - val_loss: 1.1837 - val_accuracy: 0.6480 - 43s/epoch - 2s/step\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 7: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 15s - loss: 1.1126 - accuracy: 0.6362 - val_loss: 1.0308 - val_accuracy: 0.6369 - 15s/epoch - 742ms/step\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 8: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 13s - loss: 1.0715 - accuracy: 0.6441 - val_loss: 0.9417 - val_accuracy: 0.7095 - 13s/epoch - 661ms/step\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 9: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 13s - loss: 0.8590 - accuracy: 0.7244 - val_loss: 0.8196 - val_accuracy: 0.7821 - 13s/epoch - 657ms/step\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 10: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 17s - loss: 0.8068 - accuracy: 0.7606 - val_loss: 0.7559 - val_accuracy: 0.8156 - 17s/epoch - 864ms/step\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 11: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 27s - loss: 0.6808 - accuracy: 0.7732 - val_loss: 0.6795 - val_accuracy: 0.8380 - 27s/epoch - 1s/step\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 12: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 20s - loss: 0.7507 - accuracy: 0.7543 - val_loss: 0.7162 - val_accuracy: 0.8492 - 20s/epoch - 1s/step\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 13: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 21s - loss: 0.6359 - accuracy: 0.7969 - val_loss: 0.7476 - val_accuracy: 0.8324 - 21s/epoch - 1s/step\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 14: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 23s - loss: 0.5741 - accuracy: 0.8094 - val_loss: 0.8787 - val_accuracy: 0.7542 - 23s/epoch - 1s/step\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 15: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 25s - loss: 0.6018 - accuracy: 0.8000 - val_loss: 0.7408 - val_accuracy: 0.7765 - 25s/epoch - 1s/step\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 16: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 0.5485 - accuracy: 0.8079 - val_loss: 0.7266 - val_accuracy: 0.8436 - 18s/epoch - 919ms/step\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 17: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 22s - loss: 0.4747 - accuracy: 0.8488 - val_loss: 0.7078 - val_accuracy: 0.8212 - 22s/epoch - 1s/step\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 18: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 22s - loss: 0.4859 - accuracy: 0.8378 - val_loss: 0.6294 - val_accuracy: 0.8156 - 22s/epoch - 1s/step\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 19: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 22s - loss: 0.4309 - accuracy: 0.8646 - val_loss: 0.5565 - val_accuracy: 0.8771 - 22s/epoch - 1s/step\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 20: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 14s - loss: 0.4523 - accuracy: 0.8551 - val_loss: 0.5950 - val_accuracy: 0.8547 - 14s/epoch - 689ms/step\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 21: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 13s - loss: 0.3830 - accuracy: 0.8709 - val_loss: 0.5550 - val_accuracy: 0.8939 - 13s/epoch - 666ms/step\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 22: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 0.3922 - accuracy: 0.8756 - val_loss: 0.5442 - val_accuracy: 0.8547 - 18s/epoch - 898ms/step\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 23: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 19s - loss: 0.3912 - accuracy: 0.8677 - val_loss: 0.6412 - val_accuracy: 0.8492 - 19s/epoch - 951ms/step\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 24: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 13s - loss: 0.4179 - accuracy: 0.8630 - val_loss: 0.4972 - val_accuracy: 0.8994 - 13s/epoch - 638ms/step\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 25: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 0.4062 - accuracy: 0.8661 - val_loss: 0.4935 - val_accuracy: 0.8883 - 18s/epoch - 899ms/step\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 26: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 0.3799 - accuracy: 0.8803 - val_loss: 0.5695 - val_accuracy: 0.8715 - 18s/epoch - 919ms/step\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 27: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 20s - loss: 0.4250 - accuracy: 0.8504 - val_loss: 0.6475 - val_accuracy: 0.8268 - 20s/epoch - 1s/step\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 28: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 20s - loss: 0.3750 - accuracy: 0.8819 - val_loss: 0.5393 - val_accuracy: 0.8827 - 20s/epoch - 1s/step\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 29: saving model to training_cp_efficient/cp.ckpt\n",
            "20/20 - 18s - loss: 0.2884 - accuracy: 0.9134 - val_loss: 0.5596 - val_accuracy: 0.8939 - 18s/epoch - 904ms/step\n",
            "Epoch 30/40\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-262b21becc7b>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m  \u001b[0;31m#@param {type:'raw'}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-70-cfb08e414112>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_generator, val_generator, EPOCHS, LEARNING_RATE)\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                  verbose=1)\n\u001b[1;32m     15\u001b[0m   \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   history = model.fit(\n\u001b[0m\u001b[1;32m     17\u001b[0m               \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m               \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# @title <p> Train Model\n",
        "EPOCHS = 40  #@param {type:'integer'}\n",
        "LEARNING_RATE = 1e-3  #@param {type:'raw'}\n",
        "checkpoint_path = \"training_cp_efficient/cp.ckpt\" #@param {type:'raw'}\n",
        "\n",
        "result = train_model(model,\n",
        "                     train_generator,\n",
        "                     val_generator, EPOCHS,\n",
        "                     LEARNING_RATE, checkpoint_path )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Export"
      ],
      "metadata": {
        "id": "epxw_T0FjpIl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p> Export Model Function\n",
        "def export_model_lite(model, export_path, quantized=True):\n",
        "  tf.saved_model.save(model, export_path)\n",
        "\n",
        "  converter = tf.lite.TFLiteConverter.from_saved_model(export_path)\n",
        "  tflite_model = converter.convert()\n",
        "\n",
        "  tflite_model_file = pathlib.Path(f'{export_path}.tflite')\n",
        "  tflite_model_file.write_bytes(tflite_model)\n",
        "\n",
        "  if quantized :\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    converter.target_spec.supported_types = [tf.float16]\n",
        "\n",
        "    tflite_models_fp16_file = pathlib.Path(f'{export_path}-quantized.tflite')\n",
        "\n",
        "    tflite_fp16_model = converter.convert()\n",
        "    tflite_models_fp16_file.write_bytes(tflite_fp16_model)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "bMNM5A6Le1GN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <p> Export Model\n",
        "export_path = 'inception-128' #@param {type:'raw'}\n",
        "export_model_lite(model, export_path, quantized=True)"
      ],
      "metadata": {
        "id": "HM0QLIZT16oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEvYUJQNyHPf"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-lrjl37EzJt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "8dc4fd64-2da4-4d9d-b286-192f6f93264c"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-88adf1417967>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# @title <p> Plot Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "source": [
        "# @title <p> Plot Loss\n",
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kq_9OdjBEOPh"
      },
      "outputs": [],
      "source": [
        "# @title <p> Plot Accuracy\n",
        "plt.plot(result.history['accuracy'])\n",
        "plt.plot(result.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbAQz7IUyILS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1395b804-4609-4c1d-f95f-fe75839cb6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    precision    recall  f1-score   support\n",
            "\n",
            "   01. Ayam Betutu       0.89      1.00      0.94         8\n",
            "02. Beberuk Terong       1.00      1.00      1.00         4\n",
            " 03. Coto Makassar       0.60      1.00      0.75         3\n",
            "         04. Gudeg       0.80      0.80      0.80         5\n",
            "   05. Kerak Telor       1.00      1.00      1.00         3\n",
            "      06. Mie Aceh       1.00      1.00      1.00         4\n",
            "   07. Nasi Kuning       1.00      1.00      1.00         4\n",
            "    08. Nasi Pecel       1.00      0.86      0.92         7\n",
            "        09. Papeda       0.75      1.00      0.86         3\n",
            "        10. Pempek       0.75      0.75      0.75         4\n",
            "       11. Peuyeum       1.00      1.00      1.00         2\n",
            "         12. Rawon       1.00      1.00      1.00         5\n",
            "       13. Rendang       1.00      0.89      0.94         9\n",
            "   14. Sate Madura       1.00      1.00      1.00         9\n",
            "        15. Serabi       1.00      0.86      0.92         7\n",
            "   16. Soto Banjar       0.50      0.67      0.57         3\n",
            " 17. Soto Lamongan       1.00      0.67      0.80         6\n",
            " 18. Tahu Sumedang       0.67      0.67      0.67         3\n",
            "\n",
            "          accuracy                           0.90        89\n",
            "         macro avg       0.89      0.90      0.88        89\n",
            "      weighted avg       0.92      0.90      0.90        89\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# @title <p> Evaluation with Test Data\n",
        "y_pred = tf.math.argmax(model(test_generator[0][0]), axis=1)\n",
        "y_true = tf.math.argmax(test_generator[0][1], axis=1)\n",
        "target_names = test_generator.class_indices.keys()\n",
        "\n",
        "eval = classification_report(y_true, y_pred, target_names = target_names)\n",
        "print(eval)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "msHKfWGPx7NG",
        "NDRz6t05rf6U",
        "NdtUk5fpyA0W"
      ],
      "gpuType": "T4",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}